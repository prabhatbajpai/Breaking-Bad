{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "December_Optimization Random_forest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabhatbajpai/Breaking-Bad/blob/main/December_Optimization_Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28sLTF5oop4v",
        "outputId": "e8fc2b1f-4336-4e71-caa7-c3b357a1be12"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwuwkqLxouRa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
        "from sklearn.svm import SVC,SVR\n",
        "from sklearn import datasets\n",
        "import scipy.stats as stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvmmXYspo5QU"
      },
      "source": [
        "df=pd.read_csv('./gdrive/My Drive/Deanonymization/WE_BC/WE_BC_December/WE_BC_Dec.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY8p8IahNoTt",
        "outputId": "2aa8965e-646e-41aa-ab15-21592f26284e"
      },
      "source": [
        "df=df.drop('hash',axis=1)\n",
        "df=df.drop('time',axis=1)\n",
        "df=df.drop('date',axis=1)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9801013 entries, 0 to 9801012\n",
            "Data columns (total 24 columns):\n",
            " #   Column            Dtype  \n",
            "---  ------            -----  \n",
            " 0   balance           float64\n",
            " 1   label             object \n",
            " 2   rec/sent          object \n",
            " 3   amount            float64\n",
            " 4   block_id          int64  \n",
            " 5   size              int64  \n",
            " 6   weight            int64  \n",
            " 7   version           int64  \n",
            " 8   lock_time         int64  \n",
            " 9   is_coinbase       int64  \n",
            " 10  has_witness       int64  \n",
            " 11  input_count       int64  \n",
            " 12  output_count      int64  \n",
            " 13  input_total       int64  \n",
            " 14  input_total_usd   float64\n",
            " 15  output_total      int64  \n",
            " 16  output_total_usd  float64\n",
            " 17  fee               int64  \n",
            " 18  fee_usd           float64\n",
            " 19  fee_per_kb        float64\n",
            " 20  fee_per_kb_usd    float64\n",
            " 21  fee_per_kwu       float64\n",
            " 22  fee_per_kwu_usd   float64\n",
            " 23  cdd_total         float64\n",
            "dtypes: float64(10), int64(12), object(2)\n",
            "memory usage: 1.8+ GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIitLr8ZNs3G"
      },
      "source": [
        "df=df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rd5g3xepFnH",
        "outputId": "d000bc03-4555-4f7a-f0f7-bacc3b890791"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 106546 entries, 147 to 9800177\n",
            "Data columns (total 24 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   balance           106546 non-null  float64\n",
            " 1   label             106546 non-null  object \n",
            " 2   rec/sent          106546 non-null  object \n",
            " 3   amount            106546 non-null  float64\n",
            " 4   block_id          106546 non-null  int64  \n",
            " 5   size              106546 non-null  int64  \n",
            " 6   weight            106546 non-null  int64  \n",
            " 7   version           106546 non-null  int64  \n",
            " 8   lock_time         106546 non-null  int64  \n",
            " 9   is_coinbase       106546 non-null  int64  \n",
            " 10  has_witness       106546 non-null  int64  \n",
            " 11  input_count       106546 non-null  int64  \n",
            " 12  output_count      106546 non-null  int64  \n",
            " 13  input_total       106546 non-null  int64  \n",
            " 14  input_total_usd   106546 non-null  float64\n",
            " 15  output_total      106546 non-null  int64  \n",
            " 16  output_total_usd  106546 non-null  float64\n",
            " 17  fee               106546 non-null  int64  \n",
            " 18  fee_usd           106546 non-null  float64\n",
            " 19  fee_per_kb        106546 non-null  float64\n",
            " 20  fee_per_kb_usd    106546 non-null  float64\n",
            " 21  fee_per_kwu       106546 non-null  float64\n",
            " 22  fee_per_kwu_usd   106546 non-null  float64\n",
            " 23  cdd_total         106546 non-null  float64\n",
            "dtypes: float64(10), int64(12), object(2)\n",
            "memory usage: 20.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mCGa4T5pSEp",
        "outputId": "3fdf1e2a-caa9-485b-b109-024bbef92643"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Exchange    77802\n",
              "Pool        14099\n",
              "Services    14070\n",
              "Gambling      575\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ4ud5XjNxiE"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "def peenc(df):\n",
        "  label_encoder=preprocessing.LabelEncoder()\n",
        "  df['label']=label_encoder.fit_transform(df['label'])\n",
        "  df['rec/sent']=label_encoder.fit_transform(df['rec/sent'])\n",
        "peenc(df) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYayIOkKq7ac"
      },
      "source": [
        "import warnings \n",
        "warnings.filterwarnings(action= 'ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azIG0dccrGVI"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D \n",
        "plt.style.use('ggplot')\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef,classification_report,roc_curve\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWcP0sfpcSV"
      },
      "source": [
        "def f1():\n",
        "  X=df.drop('label',axis=1)\n",
        "  y=df['label']\n",
        "  return X,y\n",
        "X,y=f1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmeaWTk0qo_K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "def f2():\n",
        "  X,y=f1()\n",
        "  X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)\n",
        "  norm = MinMaxScaler().fit(X_train)\n",
        "  X_train = norm.transform(X_train)\n",
        "  X_test = norm.transform(X_test)\n",
        "  sm = SMOTE(random_state = 2)\n",
        "  X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
        "  return X_train,X_test,y_train,y_test,X_train_res,y_train_res\n",
        "X_train,X_test,y_train,y_test,X_train_res,y_train_res=f2()\n",
        "def f3():\n",
        "  return X_train,X_test,y_train,y_test,X_train_res,y_train_res;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yFe2e4100tx",
        "outputId": "b9847821-7cd7-49ed-cd40-a34cd2f3fa1e"
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(X,y)\n",
        "scores = cross_val_score(clf, X, y, cv=3,scoring='accuracy')\n",
        "print(\"Accuracy:\"+ str(scores.mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.9624953920429776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf3rPNHX1MvR"
      },
      "source": [
        "**1. Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FPhunWQ1XQ4",
        "outputId": "9a012451-661a-468e-d4bf-bd85c2006887"
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': [10, 20, 30],\n",
        "    #'max_features': ['sqrt',0.5],\n",
        "    'max_depth': [15,20,30,50],\n",
        "    #'min_samples_leaf': [1,2,4,8],\n",
        "    #\"bootstrap\":[True,False],\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "grid = GridSearchCV(clf, rf_params, cv=3, scoring='accuracy')\n",
        "grid.fit(X, y)\n",
        "print(grid.best_params_)\n",
        "print(\"Accuracy:\"+ str(grid.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 15, 'n_estimators': 30}\n",
            "Accuracy:0.9600551199581489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTzEEqP91oFC"
      },
      "source": [
        "**2. Random Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThMv_acc1hZt",
        "outputId": "caba1fb7-ebe1-4c20-c32f-242521c7db3e"
      },
      "source": [
        "#Random Forest\n",
        "from scipy.stats import randint as sp_randint\n",
        "from random import randrange as sp_randrange\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': sp_randint(10,100),\n",
        "    \"max_features\":sp_randint(1,64),\n",
        "    'max_depth': sp_randint(5,50),\n",
        "    \"min_samples_split\":sp_randint(2,11),\n",
        "    \"min_samples_leaf\":sp_randint(1,11),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "n_iter_search=20 #number of iterations is set to 20, you can increase this number if time permits\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='accuracy')\n",
        "Random.fit(X, y)\n",
        "print(Random.best_params_)\n",
        "print(\"Accuracy:\"+ str(Random.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 42, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 3, 'n_estimators': 33}\n",
            "Accuracy:0.9479290201233006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBOksoFYJ6_F",
        "outputId": "6b640dfd-06a3-406f-e8a3-e9ac481a42e5"
      },
      "source": [
        "!pip install git+https://github.com/scikit-optimize/scikit-optimize.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/scikit-optimize/scikit-optimize.git\n",
            "  Cloning https://github.com/scikit-optimize/scikit-optimize.git to /tmp/pip-req-build-mnm0fmzy\n",
            "  Running command git clone -q https://github.com/scikit-optimize/scikit-optimize.git /tmp/pip-req-build-mnm0fmzy\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied (use --upgrade to upgrade): scikit-optimize==0.9.dev0 from git+https://github.com/scikit-optimize/scikit-optimize.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.9.dev0) (1.4.1)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.9.dev0) (20.4.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.9.dev0) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.9.dev0) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.9.dev0) (0.22.2.post1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize==0.9.dev0) (3.13)\n",
            "Building wheels for collected packages: scikit-optimize\n",
            "  Building wheel for scikit-optimize (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-optimize: filename=scikit_optimize-0.9.dev0-cp37-none-any.whl size=102086 sha256=97c30e5e9ac24627260a5c882d873cba22dd4423ef326846288793c4aeabc4ba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7eqwurws/wheels/11/6f/86/2b772172db85ad0b4487d67e325e535ee8e7782b2a1dfcadf5\n",
            "Successfully built scikit-optimize\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpEo079An_Nn",
        "outputId": "be09bd82-475b-44ef-e962-4d9156fc77f2"
      },
      "source": [
        "! pip install git+https://github.com/thuijskens/scikit-hyperband.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/thuijskens/scikit-hyperband.git\n",
            "  Cloning https://github.com/thuijskens/scikit-hyperband.git to /tmp/pip-req-build-ysnfqcp5\n",
            "  Running command git clone -q https://github.com/thuijskens/scikit-hyperband.git /tmp/pip-req-build-ysnfqcp5\n",
            "Requirement already satisfied (use --upgrade to upgrade): scikit-hyperband==0.0.1 from git+https://github.com/thuijskens/scikit-hyperband.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: nose>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from scikit-hyperband==0.0.1) (1.3.7)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikit-hyperband==0.0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-hyperband==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->scikit-hyperband==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->scikit-hyperband==0.0.1) (1.4.1)\n",
            "Building wheels for collected packages: scikit-hyperband\n",
            "  Building wheel for scikit-hyperband (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-hyperband: filename=scikit_hyperband-0.0.1-cp37-none-any.whl size=10362 sha256=c312d609bf2a8263291baea2dbe6d8f6e8b0e5b52edbe31e054644f1dc806031\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9fjpfh8o/wheels/9f/b0/a4/090ef56209908e0e7d583e47d3935f14593d31d9491b93cd3e\n",
            "Successfully built scikit-hyperband\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S2D41NO2C5l"
      },
      "source": [
        "**3.Hyper Band**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKJraiqa2cP8",
        "outputId": "6f37e2d6-a0ea-4fbb-dd25-932828f34bb0"
      },
      "source": [
        "#Random Forest\n",
        "from hyperband import HyperbandSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "from random import randrange as sp_randrange\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': sp_randint(10,100),\n",
        "    \"max_features\":sp_randint(1,23),\n",
        "    'max_depth': sp_randint(5,50),\n",
        "    \"min_samples_split\":sp_randint(2,11),\n",
        "    \"min_samples_leaf\":sp_randint(1,11),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=10,max_iter=100,scoring='accuracy')\n",
        "hyper.fit(X, y)\n",
        "print(hyper.best_params_)\n",
        "print(\"Accuracy:\"+ str(hyper.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 45, 'max_features': 5, 'min_samples_leaf': 7, 'min_samples_split': 3, 'n_estimators': 100}\n",
            "Accuracy:0.9608619751093425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR5t8AcR2i9B"
      },
      "source": [
        "**4. BO-GP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAooQcWh3OaY"
      },
      "source": [
        "Using BayseSearch_CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mc4ezk3a2uXT",
        "outputId": "97549d90-16d5-4cd6-b409-f478e5a299c4"
      },
      "source": [
        "from skopt import Optimizer\n",
        "from skopt import BayesSearchCV \n",
        "from skopt.space import Real, Categorical, Integer\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': Integer(10,100),\n",
        "    \"max_features\": Integer(1,23),\n",
        "    'max_depth': Integer(5,50),\n",
        "    \"min_samples_split\":Integer(2,11),\n",
        "    \"min_samples_leaf\":Integer(1,11),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, n_jobs=-1,scoring='accuracy')\n",
        "#number of iterations is set to 20, you can increase this number if time permits\n",
        "Bayes.fit(X, y)\n",
        "print(Bayes.best_params_)\n",
        "bclf = Bayes.best_estimator_\n",
        "print(\"Accuracy:\"+ str(Bayes.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('criterion', 'gini'), ('max_depth', 46), ('max_features', 5), ('min_samples_leaf', 8), ('min_samples_split', 5), ('n_estimators', 75)])\n",
            "Accuracy:0.9622885889662681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YNPbmh_3Z7q"
      },
      "source": [
        "Using skopt.gp_minimize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BFdL0D2R3mHy",
        "outputId": "3e228888-92aa-43f0-8873-67c42adefde4"
      },
      "source": [
        "#Random Forest\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "\n",
        "reg = RandomForestClassifier()\n",
        "# Define the hyperparameter configuration space\n",
        "space  = [Integer(10, 100, name='n_estimators'),\n",
        "            Integer(5, 50, name='max_depth'),\n",
        "          Integer(1, 23, name='max_features'),\n",
        "          Integer(2, 11, name='min_samples_split'),\n",
        "          Integer(1, 11, name='min_samples_leaf'),\n",
        "         Categorical(['gini', 'entropy'], name='criterion'),]\n",
        "# Define the objective function\n",
        "@use_named_args(space)\n",
        "def objective(**params):\n",
        "    reg.set_params(**params)\n",
        "\n",
        "    return -np.mean(cross_val_score(reg, X, y, cv=3, n_jobs=-1,\n",
        "                                    scoring=\"accuracy\"))\n",
        "from skopt import gp_minimize\n",
        "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
        "print(\"Accuracy:%.4f\" % -res_gp.fun)\n",
        "print(res_gp.x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.9650\n",
            "[37, 8, 7, 6, 9, 'entropy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UMdkiMbJlKOF",
        "outputId": "350fabc9-97a2-460d-f5ac-8218b941624b"
      },
      "source": [
        "!pip install  git+https://github.com/claesenm/optunity.git\n",
        "#!echo \"export PYTHONPATH=$PYTHONPATH:$(pwd)/optunity\" >> ~/.bashrc\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/claesenm/optunity.git\n",
            "  Cloning https://github.com/claesenm/optunity.git to /tmp/pip-req-build-0w4zvf60\n",
            "  Running command git clone -q https://github.com/claesenm/optunity.git /tmp/pip-req-build-0w4zvf60\n",
            "Building wheels for collected packages: Optunity\n",
            "  Building wheel for Optunity (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Optunity: filename=Optunity-1.1.1-cp37-none-any.whl size=74719 sha256=216f52f56ae35f148492dbfd0f4ce38e341430b8082769494959709c93169037\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7ih0dhze/wheels/dc/76/e2/701e215c2b189821c60cb8dff4e5eafa62f0d85c7421090f04\n",
            "Successfully built Optunity\n",
            "Installing collected packages: Optunity\n",
            "Successfully installed Optunity-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gXj2p-E2lrdI"
      },
      "source": [
        "# pip install optunity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PE0xZe2z5RJU"
      },
      "source": [
        "# ! cd  usr/local/lib/python3.7/dist-packages/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PBsb9uV3tK2"
      },
      "source": [
        "**5.PSO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-6eh16O54Z0b"
      },
      "source": [
        "# #Random Forest\n",
        "# import optunity\n",
        "# import optunity.metrics\n",
        "\n",
        "# data=X\n",
        "# labels=y.tolist()\n",
        "# # Define the hyperparameter configuration space\n",
        "# search = {\n",
        "#     'n_estimators': [10, 100],\n",
        "#     'max_features': [1, 23],\n",
        "#     'max_depth': [5,50],\n",
        "#     \"min_samples_split\":[2,11],\n",
        "#     \"min_samples_leaf\":[1,11],\n",
        "#     \"criterion\":[0,1]\n",
        "#          }\n",
        "# # Define the objective function\n",
        "# @optunity.cross_validated(x=data, y=labels, num_folds=3)\n",
        "# def performance(x_train, y_train, x_test, y_test,n_estimators=None, max_features=None,max_depth=None,min_samples_split=None,min_samples_leaf=None,criterion=None):\n",
        "#     # fit the model\n",
        "#     if criterion<0.5:\n",
        "#         cri='gini'\n",
        "#     else:\n",
        "#         cri='entropy'\n",
        "#     model = RandomForestClassifier(n_estimators=int(n_estimators),\n",
        "#                                    max_features=int(max_features),\n",
        "#                                    max_depth=int(max_depth),\n",
        "#                                    min_samples_split=int(min_samples_split),\n",
        "#                                    min_samples_leaf=int(min_samples_leaf),\n",
        "#                                    criterion=cri,\n",
        "#                                   )\n",
        "#     #predictions = model.predict(x_test)\n",
        "#     scores=np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,\n",
        "#                                     scoring=\"accuracy\"))\n",
        "#     #return optunity.metrics.roc_auc(y_test, predictions, positive=True)\n",
        "#     return scores#optunity.metrics.accuracy(y_test, predictions)\n",
        "\n",
        "# optimal_configuration, info, _ = optunity.maximize(performance,\n",
        "#                                                   solver_name='particle swarm',\n",
        "#                                                   num_evals=20,\n",
        "#                                                    **search\n",
        "#                                                   )\n",
        "# print(optimal_configuration)\n",
        "# print(\"Accuracy:\"+ str(info.optimum))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyJMgxaoKVOk"
      },
      "source": [
        "**6. GA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xXbBJJ4OKbQ5",
        "outputId": "b629f790-a1d9-4075-ca13-efa356b950c6"
      },
      "source": [
        "! pip install sklearn-deap\n",
        "# !pip install deap\n",
        "# from deap import base\n",
        "# from deap import creator\n",
        "# from deap import tools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-deap\n",
            "  Downloading https://files.pythonhosted.org/packages/52/c6/f56c220aad9d582f2e7fee598e5be4b737d2448506041c89bcc364455142/sklearn_deap-0.2.4-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (1.4.1)\n",
            "Collecting deap>=1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/d1/803c7a387d8a7e6866160b1541307f88d534da4291572fb32f69d2548afb/deap-1.3.1-cp37-cp37m-manylinux2010_x86_64.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->sklearn-deap) (1.0.1)\n",
            "Installing collected packages: deap, sklearn-deap\n",
            "Successfully installed deap-1.3.1 sklearn-deap-0.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IZ7FNS6X4m85",
        "outputId": "8e4bb94b-3c2a-480a-e7ce-60fd385839d2"
      },
      "source": [
        "! pip install evolutionary-algorithm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting evolutionary-algorithm\n",
            "  Downloading https://files.pythonhosted.org/packages/18/1f/a99c29e49b95787795d045879c108835e79700acddea06cd15a540dd7046/evolutionary_algorithm-0.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from evolutionary-algorithm) (1.19.5)\n",
            "Collecting func-timeout\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0d/bf0567477f7281d9a3926c582bfef21bff7498fc0ffd3e9de21811896a0b/func_timeout-4.3.5.tar.gz (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: func-timeout\n",
            "  Building wheel for func-timeout (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for func-timeout: filename=func_timeout-4.3.5-cp37-none-any.whl size=15079 sha256=a093f22030b7687a1e4c64fbe3ab1f9135d2b4f77b13bc9ec725beb10e383800\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/7c/4f/24f1d2d5bbff92219debe7ea19af84f76ddeb90dd4ec544f26\n",
            "Successfully built func-timeout\n",
            "Installing collected packages: func-timeout, evolutionary-algorithm\n",
            "Successfully installed evolutionary-algorithm-0.0.2 func-timeout-4.3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvY6eHLfKMHv",
        "outputId": "ed38a8ae-db76-41ce-cbc0-dfe57b7030dd"
      },
      "source": [
        "#Random Forest\n",
        "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': np.logspace(1,1.8,num = 10 ,base=20,dtype='int'),\n",
        "    'max_depth': np.logspace(1,2,num = 10 ,base=10,dtype='int'),\n",
        "    \"max_features\":np.logspace(0.2,1,num = 5 ,base=8,dtype='int'),\n",
        "    \"min_samples_split\":np.logspace(0.4, 1, num=5, base=10, dtype='int'), #[2, 3, 5, 7, 10],\n",
        "    \"min_samples_leaf\":np.logspace(0.1,1,num = 5 ,base=11,dtype='int'),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "rf_params = {\n",
        "    'n_estimators': range(10,100),\n",
        "    \"max_features\":range(1,23),\n",
        "    'max_depth': range(5,50),\n",
        "    \"min_samples_split\":range(2,11),\n",
        "    \"min_samples_leaf\":range(1,11),\n",
        "    #Categorical(name='criterion', categories=['gini','entropy'])#\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "# Set the hyperparameters of GA \n",
        "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
        "                                   params=rf_params,\n",
        "                                   scoring=\"accuracy\",\n",
        "                                   cv=3,\n",
        "                                   verbose=1,\n",
        "                                   population_size=10,\n",
        "                                   gene_mutation_prob=0.10,\n",
        "                                   gene_crossover_prob=0.5,\n",
        "                                   tournament_size=3,\n",
        "                                   generations_number=5,\n",
        "                                   n_jobs=1)\n",
        "ga1.fit(X, y)\n",
        "print(ga1.best_params_)\n",
        "print(\"Accuracy:\"+ str(ga1.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Types [1, 1, 1, 1, 1, 1] and maxint [89, 21, 44, 8, 9, 1] detected\n",
            "--- Evolve in 16038000 possible combinations ---\n",
            "gen\tnevals\tavg     \tmin     \tmax     \tstd       \n",
            "0  \t10    \t0.948576\t0.938121\t0.961444\t0.00925876\n",
            "1  \t6     \t0.954276\t0.939397\t0.961491\t0.00901795\n",
            "2  \t10    \t0.961472\t0.961444\t0.961491\t2.299e-05 \n",
            "3  \t6     \t0.961486\t0.961444\t0.961491\t1.40784e-05\n",
            "4  \t8     \t0.961349\t0.960092\t0.961491\t0.000418949\n",
            "5  \t5     \t0.961491\t0.961491\t0.961491\t0          \n",
            "Best individual is: {'n_estimators': 72, 'max_features': 3, 'max_depth': 37, 'min_samples_split': 10, 'min_samples_leaf': 10, 'criterion': 'gini'}\n",
            "with fitness: 0.9614908114804873\n",
            "{'n_estimators': 72, 'max_features': 3, 'max_depth': 37, 'min_samples_split': 10, 'min_samples_leaf': 10, 'criterion': 'gini'}\n",
            "Accuracy:0.9614908114804873\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}