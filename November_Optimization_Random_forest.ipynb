{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "November_Optimization Random_forest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabhatbajpai/Breaking-Bad/blob/main/November_Optimization_Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28sLTF5oop4v"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwuwkqLxouRa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
        "from sklearn.svm import SVC,SVR\n",
        "from sklearn import datasets\n",
        "import scipy.stats as stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvmmXYspo5QU"
      },
      "source": [
        "df=pd.read_csv('./gdrive/My Drive/Deanonymization/WE_BC/WE_BC_November/WE_BC_Nov.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY8p8IahNoTt"
      },
      "source": [
        "df=df.drop('hash',axis=1)\n",
        "df=df.drop('time',axis=1)\n",
        "df=df.drop('date',axis=1)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIitLr8ZNs3G"
      },
      "source": [
        "df=df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rd5g3xepFnH"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mCGa4T5pSEp"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ4ud5XjNxiE"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "def peenc(df):\n",
        "  label_encoder=preprocessing.LabelEncoder()\n",
        "  df['label']=label_encoder.fit_transform(df['label'])\n",
        "  df['rec/sent']=label_encoder.fit_transform(df['rec/sent'])\n",
        "peenc(df) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYayIOkKq7ac"
      },
      "source": [
        "import warnings \n",
        "warnings.filterwarnings(action= 'ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azIG0dccrGVI"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D \n",
        "plt.style.use('ggplot')\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef,classification_report,roc_curve\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWcP0sfpcSV"
      },
      "source": [
        "def f1():\n",
        "  X=df.drop('label',axis=1)\n",
        "  y=df['label']\n",
        "  return X,y\n",
        "X,y=f1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmeaWTk0qo_K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "def f2():\n",
        "  X,y=f1()\n",
        "  X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)\n",
        "  norm = MinMaxScaler().fit(X_train)\n",
        "  X_train = norm.transform(X_train)\n",
        "  X_test = norm.transform(X_test)\n",
        "  sm = SMOTE(random_state = 2)\n",
        "  X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
        "  return X_train,X_test,y_train,y_test,X_train_res,y_train_res\n",
        "X_train,X_test,y_train,y_test,X_train_res,y_train_res=f2()\n",
        "def f3():\n",
        "  return X_train,X_test,y_train,y_test,X_train_res,y_train_res;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yFe2e4100tx"
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(X,y)\n",
        "scores = cross_val_score(clf, X, y, cv=3,scoring='accuracy')\n",
        "print(\"Accuracy:\"+ str(scores.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf3rPNHX1MvR"
      },
      "source": [
        "**1. Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FPhunWQ1XQ4"
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': [10, 20, 30],\n",
        "    #'max_features': ['sqrt',0.5],\n",
        "    'max_depth': [15,20,30,50],\n",
        "    #'min_samples_leaf': [1,2,4,8],\n",
        "    #\"bootstrap\":[True,False],\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "grid = GridSearchCV(clf, rf_params, cv=3, scoring='accuracy')\n",
        "grid.fit(X, y)\n",
        "print(grid.best_params_)\n",
        "print(\"Accuracy:\"+ str(grid.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTzEEqP91oFC"
      },
      "source": [
        "**2. Random Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThMv_acc1hZt"
      },
      "source": [
        "#Random Forest\n",
        "from scipy.stats import randint as sp_randint\n",
        "from random import randrange as sp_randrange\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': sp_randint(10,100),\n",
        "    \"max_features\":sp_randint(1,64),\n",
        "    'max_depth': sp_randint(5,50),\n",
        "    \"min_samples_split\":sp_randint(2,11),\n",
        "    \"min_samples_leaf\":sp_randint(1,11),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "n_iter_search=20 #number of iterations is set to 20, you can increase this number if time permits\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='accuracy')\n",
        "Random.fit(X, y)\n",
        "print(Random.best_params_)\n",
        "print(\"Accuracy:\"+ str(Random.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBOksoFYJ6_F"
      },
      "source": [
        "!pip install git+https://github.com/scikit-optimize/scikit-optimize.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpEo079An_Nn"
      },
      "source": [
        "! pip install git+https://github.com/thuijskens/scikit-hyperband.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S2D41NO2C5l"
      },
      "source": [
        "**3.Hyper Band**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jKJraiqa2cP8"
      },
      "source": [
        "#Random Forest\n",
        "from hyperband import HyperbandSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "from random import randrange as sp_randrange\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': sp_randint(10,100),\n",
        "    \"max_features\":sp_randint(1,23),\n",
        "    'max_depth': sp_randint(5,50),\n",
        "    \"min_samples_split\":sp_randint(2,11),\n",
        "    \"min_samples_leaf\":sp_randint(1,11),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=10,max_iter=100,scoring='accuracy')\n",
        "hyper.fit(X, y)\n",
        "print(hyper.best_params_)\n",
        "print(\"Accuracy:\"+ str(hyper.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR5t8AcR2i9B"
      },
      "source": [
        "**4. BO-GP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAooQcWh3OaY"
      },
      "source": [
        "Using BayseSearch_CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mc4ezk3a2uXT"
      },
      "source": [
        "from skopt import Optimizer\n",
        "from skopt import BayesSearchCV \n",
        "from skopt.space import Real, Categorical, Integer\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': Integer(10,100),\n",
        "    \"max_features\": Integer(1,23),\n",
        "    'max_depth': Integer(5,50),\n",
        "    \"min_samples_split\":Integer(2,11),\n",
        "    \"min_samples_leaf\":Integer(1,11),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, n_jobs=-1,scoring='accuracy')\n",
        "#number of iterations is set to 20, you can increase this number if time permits\n",
        "Bayes.fit(X, y)\n",
        "print(Bayes.best_params_)\n",
        "bclf = Bayes.best_estimator_\n",
        "print(\"Accuracy:\"+ str(Bayes.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YNPbmh_3Z7q"
      },
      "source": [
        "Using skopt.gp_minimize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BFdL0D2R3mHy"
      },
      "source": [
        "#Random Forest\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "\n",
        "reg = RandomForestClassifier()\n",
        "# Define the hyperparameter configuration space\n",
        "space  = [Integer(10, 100, name='n_estimators'),\n",
        "            Integer(5, 50, name='max_depth'),\n",
        "          Integer(1, 23, name='max_features'),\n",
        "          Integer(2, 11, name='min_samples_split'),\n",
        "          Integer(1, 11, name='min_samples_leaf'),\n",
        "         Categorical(['gini', 'entropy'], name='criterion'),]\n",
        "# Define the objective function\n",
        "@use_named_args(space)\n",
        "def objective(**params):\n",
        "    reg.set_params(**params)\n",
        "\n",
        "    return -np.mean(cross_val_score(reg, X, y, cv=3, n_jobs=-1,\n",
        "                                    scoring=\"accuracy\"))\n",
        "from skopt import gp_minimize\n",
        "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
        "print(\"Accuracy:%.4f\" % -res_gp.fun)\n",
        "print(res_gp.x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UMdkiMbJlKOF"
      },
      "source": [
        "!pip install  git+https://github.com/claesenm/optunity.git\n",
        "#!echo \"export PYTHONPATH=$PYTHONPATH:$(pwd)/optunity\" >> ~/.bashrc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gXj2p-E2lrdI"
      },
      "source": [
        "# pip install optunity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PE0xZe2z5RJU"
      },
      "source": [
        "# ! cd  usr/local/lib/python3.7/dist-packages/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PBsb9uV3tK2"
      },
      "source": [
        "**5.PSO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-6eh16O54Z0b"
      },
      "source": [
        "# #Random Forest\n",
        "# import optunity\n",
        "# import optunity.metrics\n",
        "\n",
        "# data=X\n",
        "# labels=y.tolist()\n",
        "# # Define the hyperparameter configuration space\n",
        "# search = {\n",
        "#     'n_estimators': [10, 100],\n",
        "#     'max_features': [1, 23],\n",
        "#     'max_depth': [5,50],\n",
        "#     \"min_samples_split\":[2,11],\n",
        "#     \"min_samples_leaf\":[1,11],\n",
        "#     \"criterion\":[0,1]\n",
        "#          }\n",
        "# # Define the objective function\n",
        "# @optunity.cross_validated(x=data, y=labels, num_folds=3)\n",
        "# def performance(x_train, y_train, x_test, y_test,n_estimators=None, max_features=None,max_depth=None,min_samples_split=None,min_samples_leaf=None,criterion=None):\n",
        "#     # fit the model\n",
        "#     if criterion<0.5:\n",
        "#         cri='gini'\n",
        "#     else:\n",
        "#         cri='entropy'\n",
        "#     model = RandomForestClassifier(n_estimators=int(n_estimators),\n",
        "#                                    max_features=int(max_features),\n",
        "#                                    max_depth=int(max_depth),\n",
        "#                                    min_samples_split=int(min_samples_split),\n",
        "#                                    min_samples_leaf=int(min_samples_leaf),\n",
        "#                                    criterion=cri,\n",
        "#                                   )\n",
        "#     #predictions = model.predict(x_test)\n",
        "#     scores=np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,\n",
        "#                                     scoring=\"accuracy\"))\n",
        "#     #return optunity.metrics.roc_auc(y_test, predictions, positive=True)\n",
        "#     return scores#optunity.metrics.accuracy(y_test, predictions)\n",
        "\n",
        "# optimal_configuration, info, _ = optunity.maximize(performance,\n",
        "#                                                   solver_name='particle swarm',\n",
        "#                                                   num_evals=20,\n",
        "#                                                    **search\n",
        "#                                                   )\n",
        "# print(optimal_configuration)\n",
        "# print(\"Accuracy:\"+ str(info.optimum))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyJMgxaoKVOk"
      },
      "source": [
        "**6. GA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXbBJJ4OKbQ5"
      },
      "source": [
        "! pip install sklearn-deap\n",
        "# !pip install deap\n",
        "# from deap import base\n",
        "# from deap import creator\n",
        "# from deap import tools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ7FNS6X4m85"
      },
      "source": [
        "! pip install evolutionary-algorithm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvY6eHLfKMHv"
      },
      "source": [
        "#Random Forest\n",
        "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': np.logspace(1,1.8,num = 10 ,base=20,dtype='int'),\n",
        "    'max_depth': np.logspace(1,2,num = 10 ,base=10,dtype='int'),\n",
        "    \"max_features\":np.logspace(0.2,1,num = 5 ,base=8,dtype='int'),\n",
        "    \"min_samples_split\":np.logspace(0.4, 1, num=5, base=10, dtype='int'), #[2, 3, 5, 7, 10],\n",
        "    \"min_samples_leaf\":np.logspace(0.1,1,num = 5 ,base=11,dtype='int'),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "rf_params = {\n",
        "    'n_estimators': range(10,100),\n",
        "    \"max_features\":range(1,23),\n",
        "    'max_depth': range(5,50),\n",
        "    \"min_samples_split\":range(2,11),\n",
        "    \"min_samples_leaf\":range(1,11),\n",
        "    #Categorical(name='criterion', categories=['gini','entropy'])#\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "# Set the hyperparameters of GA \n",
        "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
        "                                   params=rf_params,\n",
        "                                   scoring=\"accuracy\",\n",
        "                                   cv=3,\n",
        "                                   verbose=1,\n",
        "                                   population_size=10,\n",
        "                                   gene_mutation_prob=0.10,\n",
        "                                   gene_crossover_prob=0.5,\n",
        "                                   tournament_size=3,\n",
        "                                   generations_number=5,\n",
        "                                   n_jobs=1)\n",
        "ga1.fit(X, y)\n",
        "print(ga1.best_params_)\n",
        "print(\"Accuracy:\"+ str(ga1.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}