{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "January_Optimization Random_forest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prabhatbajpai/Breaking-Bad/blob/main/January_Optimization_Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28sLTF5oop4v",
        "outputId": "630e493f-d2f8-4513-b1e0-6ee3a087442a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwuwkqLxouRa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
        "from sklearn.svm import SVC,SVR\n",
        "from sklearn import datasets\n",
        "import scipy.stats as stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvmmXYspo5QU"
      },
      "source": [
        "df=pd.read_csv('./gdrive/My Drive/Deanonymization/WE_BC/WE_BC_January/WE_BC_Jan.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY8p8IahNoTt",
        "outputId": "e1fec151-ebe3-4373-d03a-7998f287d868"
      },
      "source": [
        "df=df.drop('hash',axis=1)\n",
        "df=df.drop('time',axis=1)\n",
        "df=df.drop('date',axis=1)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10209236 entries, 0 to 10209235\n",
            "Data columns (total 24 columns):\n",
            " #   Column            Dtype  \n",
            "---  ------            -----  \n",
            " 0   balance           float64\n",
            " 1   label             object \n",
            " 2   rec/sent          object \n",
            " 3   amount            float64\n",
            " 4   block_id          int64  \n",
            " 5   size              int64  \n",
            " 6   weight            int64  \n",
            " 7   version           int64  \n",
            " 8   lock_time         int64  \n",
            " 9   is_coinbase       int64  \n",
            " 10  has_witness       int64  \n",
            " 11  input_count       int64  \n",
            " 12  output_count      int64  \n",
            " 13  input_total       int64  \n",
            " 14  input_total_usd   float64\n",
            " 15  output_total      int64  \n",
            " 16  output_total_usd  float64\n",
            " 17  fee               int64  \n",
            " 18  fee_usd           float64\n",
            " 19  fee_per_kb        float64\n",
            " 20  fee_per_kb_usd    float64\n",
            " 21  fee_per_kwu       float64\n",
            " 22  fee_per_kwu_usd   float64\n",
            " 23  cdd_total         float64\n",
            "dtypes: float64(10), int64(12), object(2)\n",
            "memory usage: 1.8+ GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIitLr8ZNs3G"
      },
      "source": [
        "df=df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rd5g3xepFnH",
        "outputId": "6d359d26-c2ab-4466-b151-bf52a6b767aa"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 202036 entries, 65 to 10202009\n",
            "Data columns (total 24 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   balance           202036 non-null  float64\n",
            " 1   label             202036 non-null  object \n",
            " 2   rec/sent          202036 non-null  object \n",
            " 3   amount            202036 non-null  float64\n",
            " 4   block_id          202036 non-null  int64  \n",
            " 5   size              202036 non-null  int64  \n",
            " 6   weight            202036 non-null  int64  \n",
            " 7   version           202036 non-null  int64  \n",
            " 8   lock_time         202036 non-null  int64  \n",
            " 9   is_coinbase       202036 non-null  int64  \n",
            " 10  has_witness       202036 non-null  int64  \n",
            " 11  input_count       202036 non-null  int64  \n",
            " 12  output_count      202036 non-null  int64  \n",
            " 13  input_total       202036 non-null  int64  \n",
            " 14  input_total_usd   202036 non-null  float64\n",
            " 15  output_total      202036 non-null  int64  \n",
            " 16  output_total_usd  202036 non-null  float64\n",
            " 17  fee               202036 non-null  int64  \n",
            " 18  fee_usd           202036 non-null  float64\n",
            " 19  fee_per_kb        202036 non-null  float64\n",
            " 20  fee_per_kb_usd    202036 non-null  float64\n",
            " 21  fee_per_kwu       202036 non-null  float64\n",
            " 22  fee_per_kwu_usd   202036 non-null  float64\n",
            " 23  cdd_total         202036 non-null  float64\n",
            "dtypes: float64(10), int64(12), object(2)\n",
            "memory usage: 38.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mCGa4T5pSEp",
        "outputId": "d4e1adc6-f0d0-48c2-c41e-4d8ac0a76d95"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Exchange        168925\n",
              "Mining_pools     27838\n",
              "Services          4663\n",
              "Gambling           610\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ4ud5XjNxiE"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "def peenc(df):\n",
        "  label_encoder=preprocessing.LabelEncoder()\n",
        "  df['label']=label_encoder.fit_transform(df['label'])\n",
        "  df['rec/sent']=label_encoder.fit_transform(df['rec/sent'])\n",
        "peenc(df) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYayIOkKq7ac"
      },
      "source": [
        "import warnings \n",
        "warnings.filterwarnings(action= 'ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azIG0dccrGVI"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D \n",
        "plt.style.use('ggplot')\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef,classification_report,roc_curve\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKWcP0sfpcSV"
      },
      "source": [
        "def f1():\n",
        "  X=df.drop('label',axis=1)\n",
        "  y=df['label']\n",
        "  return X,y\n",
        "X,y=f1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmeaWTk0qo_K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "def f2():\n",
        "  X,y=f1()\n",
        "  X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)\n",
        "  norm = MinMaxScaler().fit(X_train)\n",
        "  X_train = norm.transform(X_train)\n",
        "  X_test = norm.transform(X_test)\n",
        "  sm = SMOTE(random_state = 2)\n",
        "  X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
        "  return X_train,X_test,y_train,y_test,X_train_res,y_train_res\n",
        "X_train,X_test,y_train,y_test,X_train_res,y_train_res=f2()\n",
        "def f3():\n",
        "  return X_train,X_test,y_train,y_test,X_train_res,y_train_res;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yFe2e4100tx",
        "outputId": "db699eb1-6a98-4bd8-b7a6-20f6c357a22f"
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "clf.fit(X,y)\n",
        "scores = cross_val_score(clf, X, y, cv=3,scoring='accuracy')\n",
        "print(\"Accuracy:\"+ str(scores.mean()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.8139235395051503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf3rPNHX1MvR"
      },
      "source": [
        "**1. Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FPhunWQ1XQ4",
        "outputId": "f69d6965-6ebd-4449-99d2-913d4ee91ae1"
      },
      "source": [
        "#Random Forest\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': [10, 20, 30],\n",
        "    #'max_features': ['sqrt',0.5],\n",
        "    'max_depth': [15,20,30,50],\n",
        "    #'min_samples_leaf': [1,2,4,8],\n",
        "    #\"bootstrap\":[True,False],\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "grid = GridSearchCV(clf, rf_params, cv=3, scoring='accuracy')\n",
        "grid.fit(X, y)\n",
        "print(grid.best_params_)\n",
        "print(\"Accuracy:\"+ str(grid.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 20, 'n_estimators': 20}\n",
            "Accuracy:0.920395123502189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTzEEqP91oFC"
      },
      "source": [
        "**2. Random Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThMv_acc1hZt",
        "outputId": "6150fc07-d243-44ff-9943-1759175c5e0b"
      },
      "source": [
        "#Random Forest\n",
        "from scipy.stats import randint as sp_randint\n",
        "from random import randrange as sp_randrange\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': sp_randint(10,100),\n",
        "    \"max_features\":sp_randint(1,64),\n",
        "    'max_depth': sp_randint(5,50),\n",
        "    \"min_samples_split\":sp_randint(2,11),\n",
        "    \"min_samples_leaf\":sp_randint(1,11),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "n_iter_search=20 #number of iterations is set to 20, you can increase this number if time permits\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "Random = RandomizedSearchCV(clf, param_distributions=rf_params,n_iter=n_iter_search,cv=3,scoring='accuracy')\n",
        "Random.fit(X, y)\n",
        "print(Random.best_params_)\n",
        "print(\"Accuracy:\"+ str(Random.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'gini', 'max_depth': 49, 'max_features': 10, 'min_samples_leaf': 6, 'min_samples_split': 10, 'n_estimators': 13}\n",
            "Accuracy:0.9275473221877532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBOksoFYJ6_F",
        "outputId": "e95308b8-79e5-4525-9d3d-54b781cbdbda"
      },
      "source": [
        "!pip install git+https://github.com/scikit-optimize/scikit-optimize.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/scikit-optimize/scikit-optimize.git\n",
            "  Cloning https://github.com/scikit-optimize/scikit-optimize.git to /tmp/pip-req-build-veexyuof\n",
            "  Running command git clone -q https://github.com/scikit-optimize/scikit-optimize.git /tmp/pip-req-build-veexyuof\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyaml>=16.9\n",
            "  Using cached https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.9.dev0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.9.dev0) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.9.dev0) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize==0.9.dev0) (1.19.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize==0.9.dev0) (3.13)\n",
            "Building wheels for collected packages: scikit-optimize\n",
            "  Building wheel for scikit-optimize (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-optimize: filename=scikit_optimize-0.9.dev0-cp37-none-any.whl size=102086 sha256=5a3d17fee5b04612acefb9c9ce29475a32c48c874ddc7a7462d7c25d3852533d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dix7vi3m/wheels/11/6f/86/2b772172db85ad0b4487d67e325e535ee8e7782b2a1dfcadf5\n",
            "Successfully built scikit-optimize\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-20.4.0 scikit-optimize-0.9.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpEo079An_Nn",
        "outputId": "0f8571bd-aec8-430a-b988-7d3d56176b5b"
      },
      "source": [
        "! pip install git+https://github.com/thuijskens/scikit-hyperband.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/thuijskens/scikit-hyperband.git\n",
            "  Cloning https://github.com/thuijskens/scikit-hyperband.git to /tmp/pip-req-build-842fhk_g\n",
            "  Running command git clone -q https://github.com/thuijskens/scikit-hyperband.git /tmp/pip-req-build-842fhk_g\n",
            "Collecting nose>=1.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikit-hyperband==0.0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-hyperband==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->scikit-hyperband==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->scikit-hyperband==0.0.1) (1.0.1)\n",
            "Building wheels for collected packages: scikit-hyperband\n",
            "  Building wheel for scikit-hyperband (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-hyperband: filename=scikit_hyperband-0.0.1-cp37-none-any.whl size=10362 sha256=0a803646040c0ea0d654e45a03fb8d0186f43c83ff3038727232fc9d53764a97\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4_dgb5wk/wheels/9f/b0/a4/090ef56209908e0e7d583e47d3935f14593d31d9491b93cd3e\n",
            "Successfully built scikit-hyperband\n",
            "Installing collected packages: nose, scikit-hyperband\n",
            "Successfully installed nose-1.3.7 scikit-hyperband-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S2D41NO2C5l"
      },
      "source": [
        "**3.Hyper Band**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKJraiqa2cP8",
        "outputId": "940b18b7-c95c-436d-9a07-b0cb8896258c"
      },
      "source": [
        "#Random Forest\n",
        "from hyperband import HyperbandSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "from random import randrange as sp_randrange\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': sp_randint(10,100),\n",
        "    \"max_features\":sp_randint(1,23),\n",
        "    'max_depth': sp_randint(5,50),\n",
        "    \"min_samples_split\":sp_randint(2,11),\n",
        "    \"min_samples_leaf\":sp_randint(1,11),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "hyper = HyperbandSearchCV(clf, param_distributions =rf_params,cv=3,min_iter=10,max_iter=100,scoring='accuracy')\n",
        "hyper.fit(X, y)\n",
        "print(hyper.best_params_)\n",
        "print(\"Accuracy:\"+ str(hyper.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'criterion': 'entropy', 'max_depth': 11, 'max_features': 1, 'min_samples_leaf': 9, 'min_samples_split': 8, 'n_estimators': 33}\n",
            "Accuracy:0.9374764893385338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR5t8AcR2i9B"
      },
      "source": [
        "**4. BO-GP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAooQcWh3OaY"
      },
      "source": [
        "Using BayseSearch_CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mc4ezk3a2uXT",
        "outputId": "c0d4c2be-80a8-46fb-dfeb-a62e24b7afa6"
      },
      "source": [
        "from skopt import Optimizer\n",
        "from skopt import BayesSearchCV \n",
        "from skopt.space import Real, Categorical, Integer\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': Integer(10,100),\n",
        "    \"max_features\": Integer(1,23),\n",
        "    'max_depth': Integer(5,50),\n",
        "    \"min_samples_split\":Integer(2,11),\n",
        "    \"min_samples_leaf\":Integer(1,11),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "Bayes = BayesSearchCV(clf, rf_params,cv=3,n_iter=20, n_jobs=-1,scoring='accuracy')\n",
        "#number of iterations is set to 20, you can increase this number if time permits\n",
        "Bayes.fit(X, y)\n",
        "print(Bayes.best_params_)\n",
        "bclf = Bayes.best_estimator_\n",
        "print(\"Accuracy:\"+ str(Bayes.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('criterion', 'gini'), ('max_depth', 5), ('max_features', 1), ('min_samples_leaf', 11), ('min_samples_split', 11), ('n_estimators', 10)])\n",
            "Accuracy:0.930982597160902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YNPbmh_3Z7q"
      },
      "source": [
        "Using skopt.gp_minimize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BFdL0D2R3mHy",
        "outputId": "675cae70-0970-4a99-9f5e-d23ff8e0ec25"
      },
      "source": [
        "#Random Forest\n",
        "from skopt.space import Real, Integer\n",
        "from skopt.utils import use_named_args\n",
        "\n",
        "reg = RandomForestClassifier()\n",
        "# Define the hyperparameter configuration space\n",
        "space  = [Integer(10, 100, name='n_estimators'),\n",
        "            Integer(5, 50, name='max_depth'),\n",
        "          Integer(1, 23, name='max_features'),\n",
        "          Integer(2, 11, name='min_samples_split'),\n",
        "          Integer(1, 11, name='min_samples_leaf'),\n",
        "         Categorical(['gini', 'entropy'], name='criterion'),]\n",
        "# Define the objective function\n",
        "@use_named_args(space)\n",
        "def objective(**params):\n",
        "    reg.set_params(**params)\n",
        "\n",
        "    return -np.mean(cross_val_score(reg, X, y, cv=3, n_jobs=-1,\n",
        "                                    scoring=\"accuracy\"))\n",
        "from skopt import gp_minimize\n",
        "res_gp = gp_minimize(objective, space, n_calls=20, random_state=0)\n",
        "print(\"Accuracy:%.4f\" % -res_gp.fun)\n",
        "print(res_gp.x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.9693\n",
            "[100, 5, 1, 2, 5, 'entropy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UMdkiMbJlKOF",
        "outputId": "9d0ce4dd-f23b-4eb2-de11-ce09e8a1becb"
      },
      "source": [
        "!pip install  git+https://github.com/claesenm/optunity.git\n",
        "#!echo \"export PYTHONPATH=$PYTHONPATH:$(pwd)/optunity\" >> ~/.bashrc\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/claesenm/optunity.git\n",
            "  Cloning https://github.com/claesenm/optunity.git to /tmp/pip-req-build-ii632npz\n",
            "  Running command git clone -q https://github.com/claesenm/optunity.git /tmp/pip-req-build-ii632npz\n",
            "Building wheels for collected packages: Optunity\n",
            "  Building wheel for Optunity (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Optunity: filename=Optunity-1.1.1-cp37-none-any.whl size=74719 sha256=4b66b7e8ca7211fd762f06a71c843371b0adcd59b0f13fea79472b3a2758037c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3nzt8472/wheels/dc/76/e2/701e215c2b189821c60cb8dff4e5eafa62f0d85c7421090f04\n",
            "Successfully built Optunity\n",
            "Installing collected packages: Optunity\n",
            "Successfully installed Optunity-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gXj2p-E2lrdI"
      },
      "source": [
        "# pip install optunity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PE0xZe2z5RJU"
      },
      "source": [
        "# ! cd  usr/local/lib/python3.7/dist-packages/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PBsb9uV3tK2"
      },
      "source": [
        "**5.PSO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-6eh16O54Z0b"
      },
      "source": [
        "# #Random Forest\n",
        "# import optunity\n",
        "# import optunity.metrics\n",
        "\n",
        "# data=X\n",
        "# labels=y.tolist()\n",
        "# # Define the hyperparameter configuration space\n",
        "# search = {\n",
        "#     'n_estimators': [10, 100],\n",
        "#     'max_features': [1, 23],\n",
        "#     'max_depth': [5,50],\n",
        "#     \"min_samples_split\":[2,11],\n",
        "#     \"min_samples_leaf\":[1,11],\n",
        "#     \"criterion\":[0,1]\n",
        "#          }\n",
        "# # Define the objective function\n",
        "# @optunity.cross_validated(x=data, y=labels, num_folds=3)\n",
        "# def performance(x_train, y_train, x_test, y_test,n_estimators=None, max_features=None,max_depth=None,min_samples_split=None,min_samples_leaf=None,criterion=None):\n",
        "#     # fit the model\n",
        "#     if criterion<0.5:\n",
        "#         cri='gini'\n",
        "#     else:\n",
        "#         cri='entropy'\n",
        "#     model = RandomForestClassifier(n_estimators=int(n_estimators),\n",
        "#                                    max_features=int(max_features),\n",
        "#                                    max_depth=int(max_depth),\n",
        "#                                    min_samples_split=int(min_samples_split),\n",
        "#                                    min_samples_leaf=int(min_samples_leaf),\n",
        "#                                    criterion=cri,\n",
        "#                                   )\n",
        "#     #predictions = model.predict(x_test)\n",
        "#     scores=np.mean(cross_val_score(model, X, y, cv=3, n_jobs=-1,\n",
        "#                                     scoring=\"accuracy\"))\n",
        "#     #return optunity.metrics.roc_auc(y_test, predictions, positive=True)\n",
        "#     return scores#optunity.metrics.accuracy(y_test, predictions)\n",
        "\n",
        "# optimal_configuration, info, _ = optunity.maximize(performance,\n",
        "#                                                   solver_name='particle swarm',\n",
        "#                                                   num_evals=20,\n",
        "#                                                    **search\n",
        "#                                                   )\n",
        "# print(optimal_configuration)\n",
        "# print(\"Accuracy:\"+ str(info.optimum))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyJMgxaoKVOk"
      },
      "source": [
        "**6. GA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xXbBJJ4OKbQ5",
        "outputId": "462e1877-f0d6-4ed6-ae3f-779927284ed4"
      },
      "source": [
        "! pip install sklearn-deap\n",
        "# !pip install deap\n",
        "# from deap import base\n",
        "# from deap import creator\n",
        "# from deap import tools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn-deap\n",
            "  Downloading https://files.pythonhosted.org/packages/52/c6/f56c220aad9d582f2e7fee598e5be4b737d2448506041c89bcc364455142/sklearn_deap-0.2.4-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-deap) (0.22.2.post1)\n",
            "Collecting deap>=1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/d1/803c7a387d8a7e6866160b1541307f88d534da4291572fb32f69d2548afb/deap-1.3.1-cp37-cp37m-manylinux2010_x86_64.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->sklearn-deap) (1.0.1)\n",
            "Installing collected packages: deap, sklearn-deap\n",
            "Successfully installed deap-1.3.1 sklearn-deap-0.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IZ7FNS6X4m85",
        "outputId": "bc830a81-5dd2-48c6-f27c-ed9814f3d45a"
      },
      "source": [
        "! pip install evolutionary-algorithm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting evolutionary-algorithm\n",
            "  Downloading https://files.pythonhosted.org/packages/18/1f/a99c29e49b95787795d045879c108835e79700acddea06cd15a540dd7046/evolutionary_algorithm-0.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from evolutionary-algorithm) (1.19.5)\n",
            "Collecting func-timeout\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/0d/bf0567477f7281d9a3926c582bfef21bff7498fc0ffd3e9de21811896a0b/func_timeout-4.3.5.tar.gz (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: func-timeout\n",
            "  Building wheel for func-timeout (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for func-timeout: filename=func_timeout-4.3.5-cp37-none-any.whl size=15079 sha256=f5185d5c92855988312cb6ba02fa1c3818a83d2fdef54cb6cc05990a8cbf16b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/7c/4f/24f1d2d5bbff92219debe7ea19af84f76ddeb90dd4ec544f26\n",
            "Successfully built func-timeout\n",
            "Installing collected packages: func-timeout, evolutionary-algorithm\n",
            "Successfully installed evolutionary-algorithm-0.0.2 func-timeout-4.3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rvY6eHLfKMHv",
        "outputId": "efc262c7-1bd7-4294-e180-d69102b0b50d"
      },
      "source": [
        "#Random Forest\n",
        "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
        "# Define the hyperparameter configuration space\n",
        "rf_params = {\n",
        "    'n_estimators': np.logspace(1,1.8,num = 10 ,base=20,dtype='int'),\n",
        "    'max_depth': np.logspace(1,2,num = 10 ,base=10,dtype='int'),\n",
        "    \"max_features\":np.logspace(0.2,1,num = 5 ,base=8,dtype='int'),\n",
        "    \"min_samples_split\":np.logspace(0.4, 1, num=5, base=10, dtype='int'), #[2, 3, 5, 7, 10],\n",
        "    \"min_samples_leaf\":np.logspace(0.1,1,num = 5 ,base=11,dtype='int'),\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "rf_params = {\n",
        "    'n_estimators': range(10,100),\n",
        "    \"max_features\":range(1,23),\n",
        "    'max_depth': range(5,50),\n",
        "    \"min_samples_split\":range(2,11),\n",
        "    \"min_samples_leaf\":range(1,11),\n",
        "    #Categorical(name='criterion', categories=['gini','entropy'])#\n",
        "    \"criterion\":['gini','entropy']\n",
        "}\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "# Set the hyperparameters of GA \n",
        "ga1 = EvolutionaryAlgorithmSearchCV(estimator=clf,\n",
        "                                   params=rf_params,\n",
        "                                   scoring=\"accuracy\",\n",
        "                                   cv=3,\n",
        "                                   verbose=1,\n",
        "                                   population_size=10,\n",
        "                                   gene_mutation_prob=0.10,\n",
        "                                   gene_crossover_prob=0.5,\n",
        "                                   tournament_size=3,\n",
        "                                   generations_number=5,\n",
        "                                   n_jobs=1)\n",
        "ga1.fit(X, y)\n",
        "print(ga1.best_params_)\n",
        "print(\"Accuracy:\"+ str(ga1.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Types [1, 1, 1, 1, 1, 1] and maxint [89, 21, 44, 8, 9, 1] detected\n",
            "--- Evolve in 16038000 possible combinations ---\n",
            "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
            "0  \t10    \t0.755357\t0.724752\t0.887461\t0.0570316\n",
            "1  \t8     \t0.790747\t0.727271\t0.893435\t0.0771256\n",
            "2  \t5     \t0.844217\t0.727999\t0.930715\t0.0772707\n",
            "3  \t5     \t0.858673\t0.728024\t0.893435\t0.0652935\n",
            "4  \t7     \t0.885955\t0.824343\t0.893435\t0.0206077\n",
            "5  \t6     \t0.893435\t0.893435\t0.893435\t0        \n",
            "Best individual is: {'n_estimators': 19, 'max_features': 2, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6, 'criterion': 'entropy'}\n",
            "with fitness: 0.9307153180621276\n",
            "{'n_estimators': 19, 'max_features': 2, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 6, 'criterion': 'entropy'}\n",
            "Accuracy:0.9307153180621276\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}